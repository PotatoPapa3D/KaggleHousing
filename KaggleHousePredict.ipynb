{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa3a029",
   "metadata": {},
   "source": [
    "# Importing Data and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87278c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import scipy\n",
    "import xgboost\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, zscore, norm\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.linear_model import Ridge, ElasticNet, Lasso, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder,RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0e6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data and assigning them as training and test sets and viewing all columns that have missing values. \n",
    "\n",
    "train_d = 'train.csv'\n",
    "test_d = 'test.csv'\n",
    "train_data = pd.read_csv(train_d, index_col=\"Id\")\n",
    "test_data = pd.read_csv(test_d, index_col=\"Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90313461",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87755d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_data.corr()\n",
    "corr.SalePrice.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "fig, ax = fig, ax = plt.subplots(figsize=(12,10))\n",
    "ax = sns.heatmap(corr, mask= mask, vmax=0.4, square= True, fmt=\".1f\", annot= True)\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396fa20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_(X, y, axes, data_style=\"b.\"):\n",
    "    z = np.polyfit(X, y, 2)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(X, p(X), data_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OverallQual_pivot = train_data.pivot_table(index='OverallQual',values='SalePrice', aggfunc=np.mean)\n",
    "GarageCars_pivot = train_data.pivot_table(index='GarageCars',values='SalePrice', aggfunc=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482259cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "OverallQual_pivot.plot(kind='bar',color='blue')\n",
    "plt.xlabel('Overall Quality')\n",
    "plt.ylabel('Mean Sale Price')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "GarageCars_pivot.plot(kind='bar',color='blue')\n",
    "plt.xlabel('Overall Quality')\n",
    "plt.ylabel('Mean Sale Price')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "plot_(train_data.GrLivArea, train_data.SalePrice, axes = [0, 500000, 0, 4000], data_style=\"b.\")\n",
    "plt.xlabel('Above Ground Living Area')\n",
    "plt.ylabel('Mean Sale Price')\n",
    "plt.show()\n",
    "\n",
    "plot_(train_data.GarageArea, train_data.SalePrice, axes = [0, 500000, 0, 4000], data_style=\"b.\")\n",
    "plt.xlabel('Total Garage Area')\n",
    "plt.ylabel('Mean Sale Price')\n",
    "plt.show()\n",
    "\n",
    "plot_(train_data.TotalBsmtSF, train_data.SalePrice, axes = [0, 500000, 0, 4000], data_style=\"b.\")\n",
    "plt.xlabel('Total Basement Squarefootage')\n",
    "plt.ylabel('Mean Sale Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de02f9",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddaa591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining training and test data to deal with missing values\n",
    "all_data = pd.concat([train_data.drop(\"SalePrice\",axis=1),test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8791a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_df = pd.DataFrame(all_data.isna().sum().sort_values(ascending=False))\n",
    "na_df.head(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b9ef2d",
   "metadata": {},
   "source": [
    "From the text file that was shared we learn the following about the columns and what missing values mean:\n",
    "\n",
    "PoolQC: No pool\n",
    "\n",
    "MiscFeature: No miscellaneous feature\n",
    "\n",
    "Alley: No alley access\n",
    "\n",
    "Fence: No Fence\n",
    "\n",
    "FireplaceQu: No Fireplace\n",
    "\n",
    "LotFrontage: No info on missing values. Description given: Linear feet of street connected to property\n",
    "\n",
    "GarageYrBlt, GarageCond, GarageType, GarageFinish, GarageQual: No Garage\n",
    "\n",
    "BsmtFinType2, BsmtExposure: No Basement\n",
    "\n",
    "BsmtQual, BsmtCond, BsmtFinType1: No basement\n",
    "\n",
    "MasVnrArea: No info on missing values. Description given: Masonry veneer area in square feet\n",
    "\n",
    "MasVnrType: No info on missing values. Description given: Masonry veneer type.\n",
    "\n",
    "Electrical: No info on missing values. Description given: Electrical system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the following rows I am going to replace missing values with \"No Feature\": \n",
    "# 'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageCond', 'GarageType', \n",
    "# 'GarageFinish', 'GarageQual', 'BsmtExposure', 'BsmtQual', 'BsmtCond', 'BsmtFinType1'\n",
    "\n",
    "no_feat_rows = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageCond', 'GarageType', \n",
    "                'GarageFinish', 'GarageQual', 'BsmtExposure', 'BsmtQual', 'BsmtCond', 'BsmtFinType1']\n",
    "\n",
    "all_data[no_feat_rows] = all_data[no_feat_rows].fillna('No Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadc2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the following rows I am going to replace missing values with the mode for that column: \n",
    "# \"MasVnrType\", \"MSZoning\", \"Utilities\", \"Exterior1st\", \"Exterior2nd\", \"SaleType\", \"Electrical\", \n",
    "# \"KitchenQual\", \"Functional\"\n",
    "\n",
    "mode_feat_rows = [\"MasVnrType\", \"MSZoning\", \"Utilities\", \"Exterior1st\", \"Exterior2nd\", \"SaleType\", \"Electrical\", \n",
    "                  \"KitchenQual\", \"Functional\"]\n",
    "\n",
    "all_data[mode_feat_rows] = all_data.groupby(\"Neighborhood\")[mode_feat_rows].transform(lambda x:x.fillna(x.mode()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the following rows I am going to replace missing values with 0: \n",
    "# 'GarageYrBlt', 'BsmtFinType2', 'LotFrontage', 'MasVnrArea', 'BsmtHalfBath', 'BsmtFullBath', 'GarageCars',\n",
    "# 'TotalBsmtSF', 'GarageArea', 'BsmtUnfSF', 'BsmtFinSF2', 'BsmtFinSF1'\n",
    "\n",
    "zero_feat_rows = ['GarageYrBlt', 'BsmtFinType2', 'MasVnrArea', 'BsmtHalfBath', 'BsmtFullBath', 'GarageCars',\n",
    "                 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF2', 'BsmtFinSF1' ]\n",
    "\n",
    "all_data[zero_feat_rows] = all_data[zero_feat_rows].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the following rows I am going to replace missing values with the median for that column: \n",
    "# 'GarageArea', 'LotFrontage'\n",
    "\n",
    "med_feat_rows = ['GarageArea', 'LotFrontage']\n",
    "\n",
    "all_data[med_feat_rows] = all_data.groupby(\"Neighborhood\")[med_feat_rows].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f700224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "all_data['OverallCond'] = all_data['OverallCond'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a TotalSF column\n",
    "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b841e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the years and just having a column of rolling months.\n",
    "year_dict = {2006 : 0, 2007 : 12, 2008 : 24, 2009 : 36, 2010 : 48}\n",
    "all_data.replace({'YrSold' : year_dict}, inplace = True)\n",
    "all_data.YrSold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['NewMonth'] = all_data['MoSold'] + all_data['YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2549cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(['MoSold','YrSold'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d118ddbd",
   "metadata": {},
   "source": [
    "# Encoding Catagorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abcefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the LabelEncoder to Label encode all catagorical variables.\n",
    "\n",
    "cata_cols = ['FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond']\n",
    "for col in cata_cols:\n",
    "    lblenc = LabelEncoder()\n",
    "    lblenc.fit(list(all_data[col].values)) \n",
    "    all_data[col] = lblenc.transform(list(all_data[col].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd8d547",
   "metadata": {},
   "source": [
    "# Normally Distributing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edddbac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing how skewed the data is. \n",
    "train_data[\"SalePrice\"] = np.log1p(train_data[\"SalePrice\"])\n",
    "(mu, sigma) = norm.fit(train_data['SalePrice'])\n",
    "\n",
    "plt.figure(figsize = (15, 8))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(train_data['SalePrice'] , fit = norm);\n",
    "plt.legend(['Normal dist. \\n$\\mu=$ {:.2f} and $\\sigma=$ {:.2f}'.format(mu, sigma)],\n",
    "            loc = 'upper left', ncol = 2)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('SalePrice distribution')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "res = stats.probplot(train_data['SalePrice'], plot=plt, fit = norm)\n",
    "plt.show()\n",
    "y = train_data.SalePrice.values\n",
    "\n",
    "print('mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\n",
    "print(\"Skewness: %f\" % train_data['SalePrice'].skew())\n",
    "print(\"Kurtosis: %f\" % train_data['SalePrice'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793bbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the skew more toward a normal distribution\n",
    "numeric_cols = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "skewed_cols = all_data[numeric_cols].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewed = pd.DataFrame({'Skewed Columns' :skewed_cols})\n",
    "skewed = skewed[abs(skewed) > 0.75]\n",
    "\n",
    "skewed_feats = skewed.index\n",
    "lam = 0.15\n",
    "for feat in skewed_feats:\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "    all_data[feat] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68db8da",
   "metadata": {},
   "source": [
    "# Scaling and Encoding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RobustScaler to scale the data\n",
    "robust_scale_cols = all_data.select_dtypes(np.number).columns\n",
    "all_data[robust_scale_cols] = RobustScaler().fit_transform(all_data[robust_scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the data\n",
    "all_data = pd.get_dummies(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3a888",
   "metadata": {},
   "source": [
    "# Fine Tuning Hyperparameters And Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f66f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "rmse = lambda y_train, y_pred: np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "scorer = make_scorer(rmse, greater_is_better=False)\n",
    "\n",
    "def ran_search(model, grid, n_iter=100):\n",
    "    if model == xgb.XGBRegressor(n_jobs=4):\n",
    "        search0 = RandomizedSearchCV(estimator = model, param_distributions = grid, cv=kfold, n_iter = n_iter, \n",
    "                                      n_jobs = 4, random_state = 0, verbose = True)\n",
    "        return search0.fit(X_train, y_train, early_stopping_rounds = 9, verbose = True)\n",
    "    else:\n",
    "        search1 = RandomizedSearchCV(estimator = model, param_distributions = grid, cv=kfold, n_iter = n_iter, \n",
    "                                    n_jobs = 4, random_state = 0, verbose = True)\n",
    "        return search1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c242bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid = {'alpha' : np.logspace(-1, 2, 500)} \n",
    "lasso_grid = {'alpha' : np.logspace(-5, -1, 500)}\n",
    "enet_grid = {'alpha' : np.logspace(-5, .1, 500), 'l1_ratio' : np.logspace(-5, .1, 500)}\n",
    "kern_grid = {'kernel' : ['polynomial'], 'alpha' : np.logspace(-5, .1, 500), \n",
    "             'gamma': np.logspace(-5, .1, 500), 'degree' : [1,3,5,7]} \n",
    "lgbm_grid = {\"colsample_bytree\": np.linspace(0.2, 0.7, 6), \"learning_rate\": np.logspace(-3, -1, 100), \n",
    "             'n_estimators' : range(200, 3000, 200), 'max_depth' : [1, 4, 7, 10]}\n",
    "grboo_grid = {\"max_features\": np.linspace(0.2, 0.7, 6), \"learning_rate\": np.logspace(-5, -1, 100),\n",
    "             'n_estimators' : range(200, 3000, 200), 'max_depth' : [1, 4, 7, 10]} \n",
    "xgboo_grid = {'n_estimators': range(200, 3000, 200),'max_depth': [1, 4, 7, 10],'learning_rate': [0.05, 0.1, 0.20],\n",
    "           'min_child_weight': [1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2849b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data into feature, response, and test data.\n",
    "X_train = all_data.loc[train_data.index]\n",
    "X_test = all_data.loc[test_data.index]\n",
    "y_train = train_data['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681de06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outlies from the training data.\n",
    "residuals = y_train - LinearRegression().fit(X_train, y_train).predict(X_train)\n",
    "outliers = residuals[np.abs(zscore(residuals)) > 3].index\n",
    "X_train = X_train.drop(outliers)\n",
    "y_train = y_train.drop(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e198621",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = ran_search(Ridge(), ridge_grid, n_iter=100) \n",
    "lasso = ran_search(Lasso(), lasso_grid, n_iter=100)\n",
    "enet = ran_search(ElasticNet(), enet_grid, n_iter=100)\n",
    "kern = ran_search(KernelRidge(), kern_grid, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436fed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = ran_search(LGBMRegressor(), lgbm_grid, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grboo = ran_search(GradientBoostingRegressor(), grboo_grid, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e916a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboo = ran_search(xgb.XGBRegressor(n_jobs=4), xgboo_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce99def0",
   "metadata": {},
   "source": [
    "# Creating the Ensemble of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16087df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [search.best_estimator_ for search in [ridge, lasso, enet, kern, lgbm, grboo, xgboo]] \n",
    "ensemble_search = ran_search(StackingCVRegressor(models,Ridge(), cv=kfold), \n",
    "                                {\"meta_regressor__alpha\": np.logspace(-3, -1, 500)}, n_iter=15) \n",
    "models.append(ensemble_search.best_estimator_) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd8073",
   "metadata": {},
   "source": [
    "# Creating and Exporting Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = [i.predict(X_test) for i in models]\n",
    "final_prediction = np.average(final,axis=0)\n",
    "my_prediction = pd.DataFrame({\"Id\": test_data.index, \"SalePrice\": np.exp(final_prediction)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3cb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecbebf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_prediction.to_csv('JDC_Prediction2.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
